{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27c7aec3",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7613c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import mediapipe\n",
    "import mediapipe as mp\n",
    "\n",
    "#import OpenCV\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a005ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#utility that draws the whole connection\n",
    "mp_drawings = mp.solutions.drawing_utils\n",
    "\n",
    "#mediapipe solutions. landmarks from holistic\n",
    "mp_holistic = mp.solutions.holistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8785e34",
   "metadata": {},
   "source": [
    "# Make Some Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be764ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Video Feed\n",
    "\n",
    "# # Setting up video capture device\n",
    "# # 0 = built-in webcam & 2 = External webcam\n",
    "# # If want to grab a video clip, type the name of video and its file loc within (...)\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "# # Start the holistic model\n",
    "# # 'Holistic' allows me to access the Holistic estimation model\n",
    "# # '0.6' = 60%\n",
    "# with mp_holistic.Holistic(min_detection_confidence=0.6, min_tracking_confidence=0.6) as holistic:\n",
    "    \n",
    "#     #While loop to allow video to stay open till I give command to close window\n",
    "#     while cap.isOpened():\n",
    "#         #frame is the frame that will be returning\n",
    "#         #cap.read is where the webcam will capture and read the video\n",
    "#         ret, frame = cap.read()\n",
    "\n",
    "#         #Recolor Feed\n",
    "#         image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "#         #apply and set the image to be unwriteable\n",
    "#         image.flags.writeable = False\n",
    "        \n",
    "\n",
    "#         #Make Detections\n",
    "#         results = holistic.process(image)\n",
    "\n",
    "# #         #To show the coords of each types of landmarks (face, pose, hand), add '.face_landmarks' at end of \"results\" variable\n",
    "# #         print(results)\n",
    "\n",
    "#         #setting image writeable back to true to be able process it\n",
    "#         image.flags.writeable = True\n",
    "\n",
    "#         #recoloring it back to BGR b/c it will rerender back to opencv\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "#         #Draw the face landmarks\n",
    "#         mp_drawings.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS,\n",
    "#                                   mp_drawings.DrawingSpec(color=(0,155,0), thickness=1, circle_radius=1),\n",
    "#                                   mp_drawings.DrawingSpec(color=(100,155,0), thickness=1, circle_radius=1))\n",
    "        \n",
    "        \n",
    "#         #Draw the right hand landmarks\n",
    "#         mp_drawings.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "#                                   mp_drawings.DrawingSpec(color=(0,155,155), thickness=1, circle_radius=1),\n",
    "#                                   mp_drawings.DrawingSpec(color=(100,155,0), thickness=2, circle_radius=1))\n",
    "        \n",
    "#         #Draw the left hand landmarks\n",
    "#         mp_drawings.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "#                                   mp_drawings.DrawingSpec(color=(200,155,50), thickness=1, circle_radius=1),\n",
    "#                                   mp_drawings.DrawingSpec(color=(0,255,88), thickness=2, circle_radius=1))\n",
    "        \n",
    "#         #Draw the pose landmarks\n",
    "#         mp_drawings.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "#                                   mp_drawings.DrawingSpec(color=(255,155,255), thickness=1, circle_radius=1),\n",
    "#                                   mp_drawings.DrawingSpec(color=(100,155,200), thickness=2, circle_radius=1))\n",
    "\n",
    "#         #separate window will pop open to show the video feed\n",
    "#         #'Live Feed' is the name of the window\n",
    "#         cv2.imshow('Raw Live Feed', image)\n",
    "\n",
    "#         #how to turn it off\n",
    "#         #the 'e' letter will exit the live feed window\n",
    "#         if cv2.waitKey(10) & 0xFF == ord('e'):\n",
    "#             break\n",
    "        \n",
    "# #release the camera feed\n",
    "# cap.release()\n",
    "\n",
    "# #close the window\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2848df6e",
   "metadata": {},
   "source": [
    "# Calculate Angles for Joints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4db438d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(a,b,c):\n",
    "    a = np.array(a) #first point of the body\n",
    "    b = np.array(b) #second point of the body\n",
    "    c = np.array(c) #third point of the body\n",
    "    \n",
    "    #equation to get the radian\n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    #equation to find the absolute angle\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "    \n",
    "    #if the poser calcuate the angle to be greater than 180, that means that it is miscalculting\n",
    "    if angle > 180:\n",
    "        angle = 360-angle\n",
    "        \n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87363939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #showcase all the landmarks for the body\n",
    "# for ld_mk in mp_holistic.PoseLandmark:\n",
    "#     print(ld_mk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4def357c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #create variables to show the position of the given location on the screen\n",
    "# shoulder = [landmarks[mp_holistic.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_holistic.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "# elbow = [landmarks[mp_holistic.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_holistic.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "# wrist = [landmarks[mp_holistic.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_holistic.PoseLandmark.LEFT_WRIST.value].y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8df067e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #display the last image position for the shoulder, elbow, wrist\n",
    "# shoulder, elbow, wrist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a13a567e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #calculate the angle for the bicep curl\n",
    "# import numpy as np\n",
    "# calculate_angle(shoulder, elbow, wrist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5850949",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Video Feed\n",
    "\n",
    "# Setting up video capture device\n",
    "# 0 = built-in webcam & 2 = External webcam\n",
    "# If want to grab a video clip, type the name of video and its file loc within (...)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Start the holistic model\n",
    "# 'Holistic' allows me to access the Holistic estimation model\n",
    "# '0.6' = 60%\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.6, min_tracking_confidence=0.6) as holistic:\n",
    "    \n",
    "    #While loop to allow video to stay open till I give command to close window\n",
    "    while cap.isOpened():\n",
    "        #frame is the frame that will be returning\n",
    "        #cap.read is where the webcam will capture and read the video\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        #Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        #apply and set the image to be unwriteable\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "\n",
    "        #Make Detections\n",
    "        results = holistic.process(image)\n",
    "\n",
    "#         #To show the coords of each types of landmarks (face, pose, hand), add '.face_landmarks' at end of \"results\" variable\n",
    "#         print(results)\n",
    "\n",
    "        #setting image writeable back to true to be able process it\n",
    "        image.flags.writeable = True\n",
    "\n",
    "        #recoloring it back to BGR b/c it will rerender back to opencv\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        #EXTRACT LANDMARKS\n",
    "        #create a new variable \"landmarks\" that will display the landmarks on the body when the feed is live\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            #get coordinates\n",
    "            left_hip = [landmarks[mp_holistic.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_holistic.PoseLandmark.LEFT_HIP.value].y]\n",
    "            left_shoulder = [landmarks[mp_holistic.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_holistic.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            left_elbow = [landmarks[mp_holistic.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_holistic.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            left_wrist = [landmarks[mp_holistic.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_holistic.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            \n",
    "            right_hip = [landmarks[mp_holistic.PoseLandmark.RIGHT_HIP.value].x, landmarks[mp_holistic.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            right_shoulder = [landmarks[mp_holistic.PoseLandmark.RIGHT_SHOULDER.value].x, landmarks[mp_holistic.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            right_elbow = [landmarks[mp_holistic.PoseLandmark.RIGHT_ELBOW.value].x, landmarks[mp_holistic.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            right_wrist = [landmarks[mp_holistic.PoseLandmark.RIGHT_WRIST.value].x, landmarks[mp_holistic.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "            \n",
    "            #calculate angle \n",
    "            left_bicep_angle = round(calculate_angle(left_shoulder, left_elbow, left_wrist), 1)\n",
    "            left_arm_raise_angle = round(calculate_angle(left_hip, left_shoulder, left_elbow), 1)\n",
    "            \n",
    "            right_bicep_angle = round(calculate_angle(right_shoulder, right_elbow, right_wrist), 1)\n",
    "            right_arm_raise_angle = round(calculate_angle(right_hip, right_shoulder, right_elbow), 1)\n",
    "            \n",
    "            #create visual markers of the angle\n",
    "            cv2.putText(image, str(left_bicep_angle),\n",
    "                        tuple(np.multiply(left_elbow, [640,480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,0), 2, cv2.LINE_AA\n",
    "                       )\n",
    "            cv2.putText(image, str(left_arm_raise_angle),\n",
    "                        tuple(np.multiply(left_shoulder, [640,480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,0), 2, cv2.LINE_AA\n",
    "                       )\n",
    "            cv2.putText(image, str(right_bicep_angle),\n",
    "                        tuple(np.multiply(right_elbow, [640,480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2, cv2.LINE_AA\n",
    "                       )\n",
    "            cv2.putText(image, str(right_arm_raise_angle),\n",
    "                        tuple(np.multiply(right_shoulder, [640,480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2, cv2.LINE_AA\n",
    "                       )\n",
    "            \n",
    "#             print(landmarks)\n",
    "        #if it can't detect the body, it will just continue to play video feed\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        #Draw the face landmarks\n",
    "        mp_drawings.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS,\n",
    "                                  mp_drawings.DrawingSpec(color=(0,155,0), thickness=1, circle_radius=1),\n",
    "                                  mp_drawings.DrawingSpec(color=(100,155,0), thickness=1, circle_radius=1))\n",
    "        \n",
    "        \n",
    "#         #Draw the right hand landmarks\n",
    "#         mp_drawings.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "#                                   mp_drawings.DrawingSpec(color=(0,155,155), thickness=1, circle_radius=1),\n",
    "#                                   mp_drawings.DrawingSpec(color=(100,155,0), thickness=2, circle_radius=1))\n",
    "        \n",
    "#         #Draw the left hand landmarks\n",
    "#         mp_drawings.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "#                                   mp_drawings.DrawingSpec(color=(200,155,50), thickness=1, circle_radius=1),\n",
    "#                                   mp_drawings.DrawingSpec(color=(0,255,88), thickness=2, circle_radius=1))\n",
    "        \n",
    "        #Draw the pose landmarks\n",
    "        mp_drawings.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                                  mp_drawings.DrawingSpec(color=(255,155,255), thickness=1, circle_radius=1),\n",
    "                                  mp_drawings.DrawingSpec(color=(100,155,200), thickness=2, circle_radius=1))\n",
    "\n",
    "        #separate window will pop open to show the video feed\n",
    "        #'Live Feed' is the name of the window\n",
    "        cv2.imshow('Raw Live Feed', image)\n",
    "\n",
    "        #how to turn it off\n",
    "        #the 'e' letter will exit the live feed window\n",
    "        if cv2.waitKey(10) & 0xFF == ord('e'):\n",
    "            break\n",
    "        \n",
    "#release the camera feed\n",
    "cap.release()\n",
    "\n",
    "#close the window\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e96c78",
   "metadata": {},
   "source": [
    "# Capture Landmarks & Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f1c20f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19e28e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_coord_loc = len(results.pose_landmarks.landmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4fa64b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making sure that the num of landmarks are correct for pose landmarks\n",
    "pose_coord_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3d774d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#index for the name of the landmarks\n",
    "pose_landmarks = ['body class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d74b8277",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a for loop to have a name for each pose landmarks in their x,y,z coords and v = visibility\n",
    "#since the landmarks starts with 1, the \"pose_coord_loc\" will have to start at 1 and add incriment of 1\n",
    "for val in range(1, pose_coord_loc+1):\n",
    "    pose_landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09975af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['body class',\n",
       " 'x1',\n",
       " 'y1',\n",
       " 'z1',\n",
       " 'v1',\n",
       " 'x2',\n",
       " 'y2',\n",
       " 'z2',\n",
       " 'v2',\n",
       " 'x3',\n",
       " 'y3',\n",
       " 'z3',\n",
       " 'v3',\n",
       " 'x4',\n",
       " 'y4',\n",
       " 'z4',\n",
       " 'v4',\n",
       " 'x5',\n",
       " 'y5',\n",
       " 'z5',\n",
       " 'v5',\n",
       " 'x6',\n",
       " 'y6',\n",
       " 'z6',\n",
       " 'v6',\n",
       " 'x7',\n",
       " 'y7',\n",
       " 'z7',\n",
       " 'v7',\n",
       " 'x8',\n",
       " 'y8',\n",
       " 'z8',\n",
       " 'v8',\n",
       " 'x9',\n",
       " 'y9',\n",
       " 'z9',\n",
       " 'v9',\n",
       " 'x10',\n",
       " 'y10',\n",
       " 'z10',\n",
       " 'v10',\n",
       " 'x11',\n",
       " 'y11',\n",
       " 'z11',\n",
       " 'v11',\n",
       " 'x12',\n",
       " 'y12',\n",
       " 'z12',\n",
       " 'v12',\n",
       " 'x13',\n",
       " 'y13',\n",
       " 'z13',\n",
       " 'v13',\n",
       " 'x14',\n",
       " 'y14',\n",
       " 'z14',\n",
       " 'v14',\n",
       " 'x15',\n",
       " 'y15',\n",
       " 'z15',\n",
       " 'v15',\n",
       " 'x16',\n",
       " 'y16',\n",
       " 'z16',\n",
       " 'v16',\n",
       " 'x17',\n",
       " 'y17',\n",
       " 'z17',\n",
       " 'v17',\n",
       " 'x18',\n",
       " 'y18',\n",
       " 'z18',\n",
       " 'v18',\n",
       " 'x19',\n",
       " 'y19',\n",
       " 'z19',\n",
       " 'v19',\n",
       " 'x20',\n",
       " 'y20',\n",
       " 'z20',\n",
       " 'v20',\n",
       " 'x21',\n",
       " 'y21',\n",
       " 'z21',\n",
       " 'v21',\n",
       " 'x22',\n",
       " 'y22',\n",
       " 'z22',\n",
       " 'v22',\n",
       " 'x23',\n",
       " 'y23',\n",
       " 'z23',\n",
       " 'v23',\n",
       " 'x24',\n",
       " 'y24',\n",
       " 'z24',\n",
       " 'v24',\n",
       " 'x25',\n",
       " 'y25',\n",
       " 'z25',\n",
       " 'v25',\n",
       " 'x26',\n",
       " 'y26',\n",
       " 'z26',\n",
       " 'v26',\n",
       " 'x27',\n",
       " 'y27',\n",
       " 'z27',\n",
       " 'v27',\n",
       " 'x28',\n",
       " 'y28',\n",
       " 'z28',\n",
       " 'v28',\n",
       " 'x29',\n",
       " 'y29',\n",
       " 'z29',\n",
       " 'v29',\n",
       " 'x30',\n",
       " 'y30',\n",
       " 'z30',\n",
       " 'v30',\n",
       " 'x31',\n",
       " 'y31',\n",
       " 'z31',\n",
       " 'v31',\n",
       " 'x32',\n",
       " 'y32',\n",
       " 'z32',\n",
       " 'v32',\n",
       " 'x33',\n",
       " 'y33',\n",
       " 'z33',\n",
       " 'v33']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#varify to see that it has all 33 landmarks\n",
    "pose_landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4150f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new CSV writer for pose landmarks\n",
    "with open('../Capstone/data/workout_pose_coord_loc.csv', mode='w', newline='') as f:\n",
    "    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(pose_landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a4d0401a",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_coord_loc = len(results.face_landmarks.landmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a24a3e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#index for the name of the landmarks\n",
    "face_landmarks = ['face class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3a54c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a for loop to have a name for each pose landmarks in their x,y,z coords and v = visibility\n",
    "#since the landmarks starts with 1, the \"face_coord_loc\" will have to start at 1 and add incriment of 1\n",
    "for val in range(1, face_coord_loc+1):\n",
    "    face_landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13a562e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468.25"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#varify to see that it has all 468 landmarks\n",
    "len(face_landmarks)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46a62420",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new CSV writer for face landmarks\n",
    "with open('../Capstone/data/face_coord_loc.csv', mode='w', newline='') as f:\n",
    "    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(face_landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9240360a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a different class name for each type or workout move\n",
    "#change the workout name before recording so the name and workout move correlates to each other\n",
    "workout_name = 'Right_Bicep_Curl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "81969ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Video Feed\n",
    "\n",
    "# Setting up video capture device\n",
    "# 0 = built-in webcam & 2 = External webcam\n",
    "# If want to grab a video clip, type the name of video and its file loc within (...)\n",
    "cap = cv2.VideoCapture(2)\n",
    "\n",
    "# Start the holistic model\n",
    "# 'Holistic' allows me to access the Holistic estimation model\n",
    "# '0.6' = 60%\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.6, min_tracking_confidence=0.6) as holistic:\n",
    "    \n",
    "    #While loop to allow video to stay open till I give command to close window\n",
    "    while cap.isOpened():\n",
    "        #frame is the frame that will be returning\n",
    "        #cap.read is where the webcam will capture and read the video\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        #Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        #apply and set the image to be unwriteable\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "\n",
    "        #Make Detections\n",
    "        results = holistic.process(image)\n",
    "\n",
    "#         #To show the coords of each types of landmarks (face, pose, hand), add '.face_landmarks' at end of \"results\" variable\n",
    "#         print(results)\n",
    "\n",
    "        #setting image writeable back to true to be able process it\n",
    "        image.flags.writeable = True\n",
    "\n",
    "        #recoloring it back to BGR b/c it will rerender back to opencv\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        #EXTRACT LANDMARKS\n",
    "        #create a new variable \"landmarks\" that will display the landmarks on the body when the feed is live\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            #get coordinates\n",
    "            left_hip = [landmarks[mp_holistic.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_holistic.PoseLandmark.LEFT_HIP.value].y]\n",
    "            left_shoulder = [landmarks[mp_holistic.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_holistic.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            left_elbow = [landmarks[mp_holistic.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_holistic.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            left_wrist = [landmarks[mp_holistic.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_holistic.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            \n",
    "            right_hip = [landmarks[mp_holistic.PoseLandmark.RIGHT_HIP.value].x, landmarks[mp_holistic.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            right_shoulder = [landmarks[mp_holistic.PoseLandmark.RIGHT_SHOULDER.value].x, landmarks[mp_holistic.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            right_elbow = [landmarks[mp_holistic.PoseLandmark.RIGHT_ELBOW.value].x, landmarks[mp_holistic.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            right_wrist = [landmarks[mp_holistic.PoseLandmark.RIGHT_WRIST.value].x, landmarks[mp_holistic.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "            \n",
    "            #calculate angle \n",
    "            left_bicep_angle = round(calculate_angle(left_shoulder, left_elbow, left_wrist), 1)\n",
    "            left_arm_raise_angle = round(calculate_angle(left_hip, left_shoulder, left_elbow), 1)\n",
    "            \n",
    "            right_bicep_angle = round(calculate_angle(right_shoulder, right_elbow, right_wrist), 1)\n",
    "            right_arm_raise_angle = round(calculate_angle(right_hip, right_shoulder, right_elbow), 1)\n",
    "            \n",
    "            #create visual markers of the angle\n",
    "            cv2.putText(image, str(left_bicep_angle),\n",
    "                        tuple(np.multiply(left_elbow, [640,480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,0), 2, cv2.LINE_AA\n",
    "                       )\n",
    "            cv2.putText(image, str(left_arm_raise_angle),\n",
    "                        tuple(np.multiply(left_shoulder, [640,480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,0), 2, cv2.LINE_AA\n",
    "                       )\n",
    "            cv2.putText(image, str(right_bicep_angle),\n",
    "                        tuple(np.multiply(right_elbow, [640,480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2, cv2.LINE_AA\n",
    "                       )\n",
    "            cv2.putText(image, str(right_arm_raise_angle),\n",
    "                        tuple(np.multiply(right_shoulder, [640,480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2, cv2.LINE_AA\n",
    "                       )\n",
    "            \n",
    "#             print(landmarks)\n",
    "        #if it can't detect the body, it will just continue to play video feed\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        #Draw the face landmarks\n",
    "        mp_drawings.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS,\n",
    "                                  mp_drawings.DrawingSpec(color=(0,155,0), thickness=1, circle_radius=1),\n",
    "                                  mp_drawings.DrawingSpec(color=(100,155,0), thickness=1, circle_radius=1))\n",
    "        \n",
    "        \n",
    "#         #Draw the right hand landmarks\n",
    "#         mp_drawings.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "#                                   mp_drawings.DrawingSpec(color=(0,155,155), thickness=1, circle_radius=1),\n",
    "#                                   mp_drawings.DrawingSpec(color=(100,155,0), thickness=2, circle_radius=1))\n",
    "        \n",
    "#         #Draw the left hand landmarks\n",
    "#         mp_drawings.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "#                                   mp_drawings.DrawingSpec(color=(200,155,50), thickness=1, circle_radius=1),\n",
    "#                                   mp_drawings.DrawingSpec(color=(0,255,88), thickness=2, circle_radius=1))\n",
    "        \n",
    "        #Draw the pose landmarks\n",
    "        mp_drawings.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                                  mp_drawings.DrawingSpec(color=(255,155,255), thickness=1, circle_radius=1),\n",
    "                                  mp_drawings.DrawingSpec(color=(100,155,200), thickness=2, circle_radius=1))\n",
    "        \n",
    "        #export coordinates\n",
    "        try:\n",
    "            #get all the coordinates from the landmarks\n",
    "            pose_workout = results.pose_landmarks.landmark\n",
    "            \n",
    "            #extracting all the coords and converting it to an array\n",
    "            pose_workout_row = np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose_workout]).flatten()\n",
    "            \n",
    "            #covert the array to a list\n",
    "            pose_workout_row = list(pose_workout_row)\n",
    "            \n",
    "            #concatenate rows together\n",
    "            #when there are more than just one\n",
    "            total_row = pose_workout_row\n",
    "            total_row.insert(0, workout_name)\n",
    "            \n",
    "            #create a new CSV writer for pose landmarks\n",
    "            #mode='a' as append\n",
    "            with open('../Capstone/data/workout_pose_coord_loc.csv', mode='a', newline='') as f:\n",
    "                csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                csv_writer.writerow(total_row)\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        #separate window will pop open to show the video feed\n",
    "        #'Live Feed' is the name of the window\n",
    "        cv2.imshow('Raw Live Feed', image)\n",
    "\n",
    "        #how to turn it off\n",
    "        #the 'e' letter will exit the live feed window\n",
    "        if cv2.waitKey(10) & 0xFF == ord('e'):\n",
    "            break\n",
    "        \n",
    "#release the camera feed\n",
    "cap.release()\n",
    "\n",
    "#close the window\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528384ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
