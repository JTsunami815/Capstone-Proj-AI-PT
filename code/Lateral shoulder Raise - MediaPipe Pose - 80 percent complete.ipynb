{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "119b285b",
   "metadata": {},
   "source": [
    "# Install Mediapipe and Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b088a9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install mediapipe opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eb8ff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bc4e18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Video Feed\n",
    "\n",
    "# # Setting up video capture device\n",
    "# # 0 = built-in webcam & 2 = External webcam\n",
    "# cap = cv2.VideoCapture(2)\n",
    "\n",
    "# #While loop to allow video to stay open till I give command to close window\n",
    "# while cap.isOpened():\n",
    "#     #frame is the frame that will be returning\n",
    "#     #cap.read is where the webcam will capture and read the video\n",
    "#     ret, frame = cap.read()\n",
    "#     #separate window will pop open to show the video feed\n",
    "#     #'Live Feed' is the name of the window\n",
    "#     cv2.imshow('Live Feed', frame)\n",
    "    \n",
    "#     #how to turn it off\n",
    "#     #the 'e' letter will exit the live feed window\n",
    "#     if cv2.waitKey(10) & 0xFF == ord('e'):\n",
    "#         break\n",
    "# #release the camera feed\n",
    "# cap.release()\n",
    "# #close the window\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd30921b",
   "metadata": {},
   "source": [
    "# Make Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5a9e9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Video Feed\n",
    "\n",
    "# # Setting up video capture device\n",
    "# # 0 = built-in webcam & 2 = External webcam\n",
    "# cap = cv2.VideoCapture(2)\n",
    "\n",
    "# # Setup mediapipe instance\n",
    "# # 'Pose' allows me to access the Pose estimation model\n",
    "# # '0.5' = 50%\n",
    "# with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "\n",
    "#     #While loop to allow video to stay open till I give command to close window\n",
    "#     while cap.isOpened():\n",
    "#         #frame is the frame that will be returning\n",
    "#         #cap.read is where the webcam will capture and read the video\n",
    "#         ret, frame = cap.read()\n",
    "        \n",
    "#         #DETECT OBJECT AND RENDER\n",
    "#         #recolor image from BGR to RGB to allow mediapipe to read it properly\n",
    "#         image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#         #apply and set the image to be unwriteable\n",
    "#         image.flags.writeable = False\n",
    "        \n",
    "#         #make detection where the machine will process the image and storing it as 'results' in array\n",
    "#         results = pose.process(image)\n",
    "        \n",
    "#         #setting image writeable back to true to be able process it\n",
    "#         image.flags.writeable = True\n",
    "#         #recoloring it back to BGR b/c it will rerender back to opencv\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "#         #To test to make sure 'results' is running properly **CAN MARK IT WHEN TESTING IS DONE\n",
    "#         #print(results)\n",
    "        \n",
    "#         #render detection\n",
    "#         #'draw_landmarks' will draw the dots and lines on to the body\n",
    "#         #it will utilize the 'pose' and draw the shape approprately according to predesigned dot coord that will be fix\n",
    "#         #to the body\n",
    "#         #'POSE_CONNECTIONS' helps determine which landmark represents which part of the body\n",
    "#         mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "        \n",
    "#         #separate window will pop open to show the video feed from 'image'\n",
    "#         #'Live Feed' is the name of the window\n",
    "#         cv2.imshow('Live Feed', image)\n",
    "\n",
    "#         #how to turn it off\n",
    "#         #the 'e' letter will exit the live feed window\n",
    "#         if cv2.waitKey(10) & 0xFF == ord('e'):\n",
    "#             break\n",
    "            \n",
    "#     #release the camera feed\n",
    "#     cap.release()\n",
    "#     #close the window\n",
    "#     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff440ecb",
   "metadata": {},
   "source": [
    "# Determining Joints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "096a9b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Video Feed\n",
    "\n",
    "# # Setting up video capture device\n",
    "# # 0 = built-in webcam & 2 = External webcam\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "# # Setup mediapipe instance\n",
    "# # 'Pose' allows me to access the Pose estimation model\n",
    "# # '0.5' = 50%\n",
    "# with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "\n",
    "#     #While loop to allow video to stay open till I give command to close window\n",
    "#     while cap.isOpened():\n",
    "#         #frame is the frame that will be returning\n",
    "#         #cap.read is where the webcam will capture and read the video\n",
    "#         ret, frame = cap.read()\n",
    "        \n",
    "#         #DETECT OBJECT AND RENDER\n",
    "#         #recolor image from BGR to RGB to allow mediapipe to read it properly\n",
    "#         image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#         #apply and set the image to be unwriteable\n",
    "#         image.flags.writeable = False\n",
    "        \n",
    "#         #make detection where the machine will process the image and storing it as 'results' in array\n",
    "#         results = pose.process(image)\n",
    "        \n",
    "#         #setting image writeable back to true to be able process it\n",
    "#         image.flags.writeable = True\n",
    "#         #recoloring it back to BGR b/c it will rerender back to opencv\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "#         #To test to make sure 'results' is running properly **CAN MARK IT WHEN TESTING IS DONE\n",
    "#         #print(results)\n",
    "        \n",
    "#         #EXTRACT LANDMARKS\n",
    "#         #create a new variable \"landmarks\" that will display the landmarks on the body when the feed is live\n",
    "#         try:\n",
    "#             landmarks = results.pose_landmarks.landmark\n",
    "#             print(landmarks)\n",
    "#         #if it can't detect the body, it will just continue to play video feed\n",
    "#         except:\n",
    "#             pass\n",
    "        \n",
    "#         #render detection\n",
    "#         #'draw_landmarks' will draw the dots and lines on to the body\n",
    "#         #it will utilize the 'pose' and draw the shape approprately according to predesigned dot coord that will be fix\n",
    "#         #to the body\n",
    "#         #'POSE_CONNECTIONS' helps determine which landmark represents which part of the body\n",
    "#         mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "        \n",
    "#         #separate window will pop open to show the video feed from 'image'\n",
    "#         #'Live Feed' is the name of the window\n",
    "#         cv2.imshow('Live Feed', image)\n",
    "\n",
    "#         #how to turn it off\n",
    "#         #the 'e' letter will exit the live feed window\n",
    "#         if cv2.waitKey(10) & 0xFF == ord('e'):\n",
    "#             break\n",
    "#     #release the camera feed\n",
    "#     cap.release()\n",
    "#     #close the window\n",
    "#     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f89a4c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #find out the number of landmarks there are\n",
    "# len(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17754758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #showcase all the landmarks for the body\n",
    "# for ld_mk in mp_pose.PoseLandmark:\n",
    "#     print(ld_mk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c27b1cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #show an example of the landmark in x,y,z coord\n",
    "# landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cdea69",
   "metadata": {},
   "source": [
    "# Calculate Angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "494b0958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(a,b,c):\n",
    "    a = np.array(a) #first point of the body\n",
    "    b = np.array(b) #second point of the body\n",
    "    c = np.array(c) #third point of the body\n",
    "    \n",
    "    #equation to get the radian\n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    #equation to find the absolute angle\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "    \n",
    "    #if the poser calcuate the angle to be greater than 180, that means that it is miscalculting\n",
    "    if angle > 180:\n",
    "        angle = 360-angle\n",
    "        \n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83e05a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "# elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "# wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c013ba5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shoulder, elbow, wrist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a7db9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate_angle(shoulder, elbow, wrist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ee9b40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Video Feed\n",
    "\n",
    "# # Setting up video capture device\n",
    "# # 0 = built-in webcam & 2 = External webcam\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "# # Setup mediapipe instance\n",
    "# # 'Pose' allows me to access the Pose estimation model\n",
    "# # '0.5' = 50%\n",
    "# with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "\n",
    "#     #While loop to allow video to stay open till I give command to close window\n",
    "#     while cap.isOpened():\n",
    "#         #frame is the frame that will be returning\n",
    "#         #cap.read is where the webcam will capture and read the video\n",
    "#         ret, frame = cap.read()\n",
    "        \n",
    "#         #DETECT OBJECT AND RENDER\n",
    "#         #recolor image from BGR to RGB to allow mediapipe to read it properly\n",
    "#         image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#         #apply and set the image to be unwriteable\n",
    "#         image.flags.writeable = False\n",
    "        \n",
    "#         #make detection where the machine will process the image and storing it as 'results' in array\n",
    "#         results = pose.process(image)\n",
    "        \n",
    "#         #setting image writeable back to true to be able process it\n",
    "#         image.flags.writeable = True\n",
    "#         #recoloring it back to BGR b/c it will rerender back to opencv\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "#         #To test to make sure 'results' is running properly **CAN MARK IT WHEN TESTING IS DONE\n",
    "#         #print(results)\n",
    "        \n",
    "#         #EXTRACT LANDMARKS\n",
    "#         #create a new variable \"landmarks\" that will display the landmarks on the body when the feed is live\n",
    "#         try:\n",
    "#             landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "#             #get coordinates\n",
    "#             left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "#             left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "#             left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "#             left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            \n",
    "#             right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "#             right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "#             right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "#             right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "            \n",
    "#             #calculate angle \n",
    "#             left_bicep_angle = round(calculate_angle(left_shoulder, left_elbow, left_wrist), 1)\n",
    "#             left_arm_raise_angle = round(calculate_angle(left_hip, left_shoulder, left_elbow), 1)\n",
    "            \n",
    "#             right_bicep_angle = round(calculate_angle(right_shoulder, right_elbow, right_wrist), 1)\n",
    "#             right_arm_raise_angle = round(calculate_angle(right_hip, right_shoulder, right_elbow), 1)\n",
    "            \n",
    "#             #create visual markers of the angle\n",
    "#             cv2.putText(image, str(left_bicep_angle),\n",
    "#                         tuple(np.multiply(left_elbow, [640,480]).astype(int)),\n",
    "#                         cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,0), 2, cv2.LINE_AA\n",
    "#                        )\n",
    "#             cv2.putText(image, str(left_arm_raise_angle),\n",
    "#                         tuple(np.multiply(left_shoulder, [640,480]).astype(int)),\n",
    "#                         cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,0), 2, cv2.LINE_AA\n",
    "#                        )\n",
    "#             cv2.putText(image, str(right_bicep_angle),\n",
    "#                         tuple(np.multiply(right_elbow, [640,480]).astype(int)),\n",
    "#                         cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2, cv2.LINE_AA\n",
    "#                        )\n",
    "#             cv2.putText(image, str(right_arm_raise_angle),\n",
    "#                         tuple(np.multiply(right_shoulder, [640,480]).astype(int)),\n",
    "#                         cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2, cv2.LINE_AA\n",
    "#                        )\n",
    "            \n",
    "#             print(landmarks)\n",
    "#         #if it can't detect the body, it will just continue to play video feed\n",
    "#         except:\n",
    "#             pass\n",
    "        \n",
    "#         #render detection\n",
    "#         #'draw_landmarks' will draw the dots and lines on to the body\n",
    "#         #it will utilize the 'pose' and draw the shape approprately according to predesigned dot coord that will be fix\n",
    "#         #to the body\n",
    "#         #'POSE_CONNECTIONS' helps determine which landmark represents which part of the body\n",
    "#         mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "        \n",
    "#         #separate window will pop open to show the video feed from 'image'\n",
    "#         #'Live Feed' is the name of the window\n",
    "#         cv2.imshow('Live Feed', image)\n",
    "\n",
    "#         #how to turn it off\n",
    "#         #the 'e' letter will exit the live feed window\n",
    "#         if cv2.waitKey(10) & 0xFF == ord('e'):\n",
    "#             break\n",
    "#     #release the camera feed\n",
    "#     cap.release()\n",
    "#     #close the window\n",
    "#     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5094dde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cea4eb40",
   "metadata": {},
   "source": [
    "# Curl Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfc4635e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a position finder function\n",
    "def findPosition(image, draw=True):\n",
    "    lmList=[]\n",
    "    if results.pose_landmarks:\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "        for id, lm in enumerate(results.pose_landmarks.landmark):\n",
    "            h, w, c = image.shape\n",
    "            cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "            lmList.append([id, cx, cy])\n",
    "    return lmList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33e8d008",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Right Lat Raise Rep: 1\n",
      "Current Right Lat Raise Rep: 2\n",
      "Current Right Lat Raise Rep: 3\n",
      "Current Left Lat Raise Rep: 1\n",
      "Current Left Lat Raise Rep: 2\n",
      "Current Left Lat Raise Rep: 3\n",
      "Current Left Lat Raise Rep: 4\n",
      "Current Right Lat Raise Rep: 4\n",
      "Current Right Lat Raise Rep: 5\n",
      "Current Right Lat Raise Rep: 6\n",
      "Current Right Lat Raise Rep: 7\n",
      "Current Left Lat Raise Rep: 5\n",
      "Current Left Lat Raise Rep: 6\n",
      "Current Left Lat Raise Rep: 7\n",
      "Current Left Lat Raise Rep: 8\n"
     ]
    }
   ],
   "source": [
    "#Video Feed\n",
    "\n",
    "# Setting up video capture device\n",
    "# 0 = built-in webcam & 2 = External webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# #Curl counter variables\n",
    "left_lat_raise_counter = 0\n",
    "left_lat_raise_stage = None\n",
    "\n",
    "right_lat_raise_counter = 0\n",
    "right_lat_raise_stage = None\n",
    "\n",
    "# Setup mediapipe instance\n",
    "# 'Pose' allows me to access the Pose estimation model\n",
    "# '0.5' = 50%\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "\n",
    "    #While loop to allow video to stay open till I give command to close window\n",
    "    while cap.isOpened():\n",
    "        #frame is the frame that will be returning\n",
    "        #cap.read is where the webcam will capture and read the video\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        #DETECT OBJECT AND RENDER\n",
    "        #recolor image from BGR to RGB to allow mediapipe to read it properly\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        #apply and set the image to be unwriteable\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        #make detection where the machine will process the image and storing it as 'results' in array\n",
    "        results = pose.process(image)\n",
    "        \n",
    "        #setting image writeable back to true to be able process it\n",
    "        image.flags.writeable = True\n",
    "        \n",
    "        #recoloring it back to BGR b/c it will rerender back to opencv\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        lmList = findPosition(image, draw=True)\n",
    "        \n",
    "        #To test to make sure 'results' is running properly **CAN MARK IT WHEN TESTING IS DONE\n",
    "        #print(results)\n",
    "        \n",
    "        #EXTRACT LANDMARKS\n",
    "        #create a new variable \"landmarks\" that will display the landmarks on the body when the feed is live\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            #get coordinates\n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "            left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "            left_heel = [landmarks[mp_pose.PoseLandmark.LEFT_HEEL.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HEEL.value].y]\n",
    "            left_foot_index = [landmarks[mp_pose.PoseLandmark.LEFT_FOOT_INDEX.value].x, landmarks[mp_pose.PoseLandmark.LEFT_FOOT_INDEX.value].y]\n",
    "            \n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "            right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "            right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "            right_heel = [landmarks[mp_pose.PoseLandmark.RIGHT_HEEL.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_HEEL.value].y]\n",
    "            right_foot_index = [landmarks[mp_pose.PoseLandmark.RIGHT_FOOT_INDEX.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_FOOT_INDEX.value].y]\n",
    "            \n",
    "            #calculate angle \n",
    "            left_bicep_angle = round(calculate_angle(left_shoulder, left_elbow, left_wrist), 1)\n",
    "            left_arm_raise_angle = round(calculate_angle(left_hip, left_shoulder, left_elbow), 1)\n",
    "            left_side_bend_angle = round(calculate_angle(left_shoulder, left_hip, left_knee), 1)\n",
    "            left_knee_angle = round(calculate_angle(left_hip, left_knee, left_ankle), 1)\n",
    "            left_ankle_angle = round(calculate_angle(left_knee, left_ankle, left_foot_index), 1)\n",
    "            \n",
    "            right_bicep_angle = round(calculate_angle(right_shoulder, right_elbow, right_wrist), 1)\n",
    "            right_arm_raise_angle = round(calculate_angle(right_hip, right_shoulder, right_elbow), 1)\n",
    "            right_side_bend_angle = round(calculate_angle(right_shoulder, right_hip, right_knee), 1)\n",
    "            right_knee_angle = round(calculate_angle(right_hip, right_knee, right_ankle), 1)\n",
    "            right_ankle_angle = round(calculate_angle(right_knee, right_ankle, right_foot_index), 1)\n",
    "            \n",
    "            #create visual markers of the angle\n",
    "            #colour coord is in GRB instead of RGB\n",
    "            cv2.putText(image, str(left_bicep_angle),\n",
    "                        tuple(np.multiply(left_elbow, [640,480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,0), 2, cv2.LINE_AA\n",
    "                       )\n",
    "            cv2.putText(image, str(left_arm_raise_angle),\n",
    "                        tuple(np.multiply(left_shoulder, [640,480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,0), 2, cv2.LINE_AA\n",
    "                       )\n",
    "            cv2.putText(image, str(left_side_bend_angle),\n",
    "                        tuple(np.multiply(left_hip, [640,480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,0), 2, cv2.LINE_AA\n",
    "                       )\n",
    "            cv2.putText(image, str(left_knee_angle),\n",
    "                        tuple(np.multiply(left_knee, [640,480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,0), 2, cv2.LINE_AA\n",
    "                       )\n",
    "            cv2.putText(image, str(left_ankle_angle),\n",
    "                        tuple(np.multiply(left_ankle, [640,480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,0), 2, cv2.LINE_AA\n",
    "                       )\n",
    "            \n",
    "            \n",
    "            cv2.putText(image, str(right_bicep_angle),\n",
    "                        tuple(np.multiply(right_elbow, [640,480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2, cv2.LINE_AA\n",
    "                       )\n",
    "            cv2.putText(image, str(right_arm_raise_angle),\n",
    "                        tuple(np.multiply(right_shoulder, [640,480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2, cv2.LINE_AA\n",
    "                       )\n",
    "            cv2.putText(image, str(right_side_bend_angle),\n",
    "                        tuple(np.multiply(right_hip, [640,480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2, cv2.LINE_AA\n",
    "                       )\n",
    "            cv2.putText(image, str(right_knee_angle),\n",
    "                        tuple(np.multiply(right_knee, [640,480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2, cv2.LINE_AA\n",
    "                       )\n",
    "            cv2.putText(image, str(right_ankle_angle),\n",
    "                        tuple(np.multiply(right_ankle, [640,480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2, cv2.LINE_AA\n",
    "                       )\n",
    "            \n",
    "            #draw the pose annotation on the image\n",
    "            \n",
    "            #marking the shoulders circle bigger\n",
    "            #left shoulder\n",
    "            cv2.circle(image, (lmList[11][1], lmList[11][2]), 20, (0,255,255), thickness=2)\n",
    "            \n",
    "            #right shoulder\n",
    "            cv2.circle(image, (lmList[12][1], lmList[12][2]), 20, (255,255,0), thickness=2)\n",
    "            \n",
    "            #curl counter logic for left lat raise curl\n",
    "            if left_arm_raise_angle < 20 and left_bicep_angle >= 155:\n",
    "                cv2.circle(image, (lmList[11][1], lmList[11][2]), 5, (0,0,255), cv2.FILLED)\n",
    "                left_lat_raise_stage = \"DOWN\"\n",
    "                \n",
    "            if left_arm_raise_angle < 40 and left_arm_raise_angle >= 20 and left_bicep_angle >= 135:\n",
    "                cv2.circle(image, (lmList[11][1], lmList[11][2]), 10, (0,50,200), cv2.FILLED)\n",
    "                left_lat_raise_stage = \"down mid\"\n",
    "                \n",
    "            if left_arm_raise_angle < 55 and left_arm_raise_angle >= 40 and left_bicep_angle >= 135:\n",
    "                cv2.circle(image, (lmList[11][1], lmList[11][2]), 12, (0,100,150), cv2.FILLED)\n",
    "                left_lat_raise_stage = \"middle\"\n",
    "                \n",
    "            if left_arm_raise_angle < 65 and left_arm_raise_angle >= 55 and left_bicep_angle >= 135:\n",
    "                cv2.circle(image, (lmList[11][1], lmList[11][2]), 14, (0,150,100), cv2.FILLED)\n",
    "                left_lat_raise_stage = \"middle up\"\n",
    "                \n",
    "            if left_arm_raise_angle < 75 and left_arm_raise_angle >= 65 and left_bicep_angle >= 135:\n",
    "                cv2.circle(image, (lmList[11][1], lmList[11][2]), 16, (0,200,50), cv2.FILLED)\n",
    "                left_lat_raise_stage = \"almost there\"\n",
    "                \n",
    "            if left_arm_raise_angle < 90 and left_arm_raise_angle >= 75 and left_bicep_angle >= 135:\n",
    "                cv2.circle(image, (lmList[11][1], lmList[11][2]), 18, (0,225,30), cv2.FILLED)\n",
    "                left_lat_raise_stage = \"a lil more\"\n",
    "                \n",
    "            if left_arm_raise_angle < 100 and left_arm_raise_angle >= 90 and left_lat_raise_stage == \"a lil more\" \\\n",
    "                and left_bicep_angle >= 135:\n",
    "                left_lat_raise_stage = \"UP\"\n",
    "                \n",
    "                cv2.circle(image, (lmList[11][1], lmList[11][2]), 22, (255,255,255), cv2.FILLED)\n",
    "                left_lat_raise_counter +=1\n",
    "                print(f\"Current Left Lat Raise Rep: {left_lat_raise_counter}\")\n",
    "                \n",
    "            if left_arm_raise_angle > 110 and left_lat_raise_stage == 'UP':\n",
    "                left_lat_raise_stage = 'TOO HIGH, LOWER DOWN'\n",
    "            \n",
    "            #curl counter logic for right lat raise curl\n",
    "            if right_arm_raise_angle < 20 and right_bicep_angle >= 155:\n",
    "                cv2.circle(image, (lmList[12][1], lmList[12][2]), 5, (255,0,255), cv2.FILLED)\n",
    "                right_lat_raise_stage = \"DOWN\"\n",
    "                \n",
    "            if right_arm_raise_angle < 40 and right_arm_raise_angle >= 20 and right_bicep_angle >= 135:\n",
    "                cv2.circle(image, (lmList[12][1], lmList[12][2]), 10, (200,50,200), cv2.FILLED)\n",
    "                right_lat_raise_stage = \"down mid\"\n",
    "                \n",
    "            if right_arm_raise_angle < 55 and right_arm_raise_angle >= 40 and right_bicep_angle >= 135:\n",
    "                cv2.circle(image, (lmList[12][1], lmList[12][2]), 12, (150,100,150), cv2.FILLED)\n",
    "                right_lat_raise_stage = \"middle\"\n",
    "                \n",
    "            if right_arm_raise_angle < 65 and right_arm_raise_angle >= 55 and right_bicep_angle >= 135:\n",
    "                cv2.circle(image, (lmList[12][1], lmList[12][2]), 14, (100,150,100), cv2.FILLED)\n",
    "                right_lat_raise_stage = \"middle up\"\n",
    "                \n",
    "            if right_arm_raise_angle < 75 and right_arm_raise_angle >= 65 and right_bicep_angle >= 135:\n",
    "                cv2.circle(image, (lmList[12][1], lmList[12][2]), 16, (50,200,50), cv2.FILLED)\n",
    "                right_lat_raise_stage = \"almost there\"\n",
    "                \n",
    "            if right_arm_raise_angle < 90 and right_arm_raise_angle >= 75 and right_bicep_angle >= 135:\n",
    "                cv2.circle(image, (lmList[12][1], lmList[12][2]), 18, (30,225,30), cv2.FILLED)\n",
    "                right_lat_raise_stage = \"a lil more\"\n",
    "                \n",
    "            if right_arm_raise_angle < 100 and right_arm_raise_angle >=90 and right_lat_raise_stage == \"a lil more\" \\\n",
    "                and right_bicep_angle >= 135:\n",
    "                right_lat_raise_stage = \"UP\"\n",
    "                cv2.circle(image, (lmList[12][1], lmList[12][2]), 22, (255,255,255), cv2.FILLED)\n",
    "                right_lat_raise_counter +=1\n",
    "                print(f\"Current Right Lat Raise Rep: {right_lat_raise_counter}\")\n",
    "                \n",
    "            if right_arm_raise_angle > 110 and right_lat_raise_stage == 'UP':\n",
    "                right_lat_raise_stage = 'TOO HIGH, LOWER DOWN'\n",
    "                \n",
    "                \n",
    "        #if it can't detect the body, it will just continue to play video feed\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        #add raise counter\n",
    "        #setup a status box\n",
    "        cv2.rectangle(image, (0,0), (300,50), (24,117,16), -1)  #(0,0) =  start point of rectangle\n",
    "                                                                #(300,50) = end point of rectangle\n",
    "                                                                #(24,117,16) = RGB\n",
    "                                                                #-1 = fill the box with color\n",
    "        \n",
    "        cv2.rectangle(image, (350,0), (680,50), (255,117,16), -1)  #(0,0) =  start point of rectangle\n",
    "                                                                #(680,50) = end point of rectangle\n",
    "                                                                #(24,117,16) = RGB\n",
    "                                                                #-1 = fill the box with color\n",
    "        #rep data(left arm)\n",
    "        cv2.putText(image, 'LT REPS: ', (15,12),                                #(15,12) = start coord\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,0), 1, cv2.LINE_AA) #font type = hersey\n",
    "                                                                                #text size = 0.5\n",
    "                                                                                #text color = 255,255,0\n",
    "                                                                                #line thickness = 1\n",
    "                                                                                #line type = AA\n",
    "        cv2.putText(image, str(left_lat_raise_counter), (10,40),                #(10,60) = start coord\n",
    "                    cv2.FONT_HERSHEY_COMPLEX, .5, (255,255,255), 2, cv2.LINE_AA) #font type = hersey\n",
    "                                                                                #text size = 0.5\n",
    "                                                                                #text color = 255,255,255\n",
    "                                                                                #line thickness = 2\n",
    "                                                                                #line type = AA\n",
    "        #rep data(right arm)\n",
    "        cv2.putText(image, 'RT REPS: ', (365,12),                               #(365,12) = start coord\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,0), 1, cv2.LINE_AA) #font type = hersey\n",
    "                                                                                #text size = 0.5\n",
    "                                                                                #text color = 255,255,0\n",
    "                                                                                #line thickness = 1\n",
    "                                                                                #line type = AA\n",
    "        cv2.putText(image, str(right_lat_raise_counter), (360,40),              #(210,260) = start coord\n",
    "                    cv2.FONT_HERSHEY_COMPLEX, .5, (255,255,255), 2, cv2.LINE_AA) #font type = hersey\n",
    "                                                                                #text size = 0.5\n",
    "                                                                                #text color = 255,255,255\n",
    "                                                                                #line thickness = 2\n",
    "                                                                                #line type = AA\n",
    "        \n",
    "        #rep position(left arm)\n",
    "        cv2.putText(image, 'LT ARM POS: ', (120,12),                          #(165,12) = start coord\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 1, cv2.LINE_AA) #font type = hersey\n",
    "                                                                              #text size = 0.5\n",
    "                                                                              #text color = 0,255,0\n",
    "                                                                              #line thickness = 1\n",
    "                                                                              #line type = AA\n",
    "        cv2.putText(image, left_lat_raise_stage, (120,40),                      #(160,60) = start coord\n",
    "                    cv2.FONT_HERSHEY_COMPLEX, .5, (255,255,255), 1, cv2.LINE_AA)#font type = hersey\n",
    "                                                                                #text size = 1\n",
    "                                                                                #text color = 255,255,255\n",
    "                                                                                #line thickness = 2\n",
    "                                                                                #line type = AA\n",
    "        #rep position(right arm)\n",
    "        cv2.putText(image, 'RT ARM POS: ', (460,12),                          #(500,12) = start coord\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 1, cv2.LINE_AA) #font type = hersey\n",
    "                                                                              #text size = 0.5\n",
    "                                                                              #text color = 0,255,0\n",
    "                                                                              #line thickness = 1\n",
    "                                                                              #line type = AA\n",
    "        cv2.putText(image, right_lat_raise_stage, (460,40),                     #(500,60) = start coord\n",
    "                    cv2.FONT_HERSHEY_COMPLEX, .5, (255,255,255), 1, cv2.LINE_AA)#font type = hersey\n",
    "                                                                                #text size = 1\n",
    "                                                                                #text color = 255,255,255\n",
    "                                                                                #line thickness = 2\n",
    "                                                                                #line type = AA\n",
    "                \n",
    "        #render detection\n",
    "        #'draw_landmarks' will draw the dots and lines on to the body\n",
    "        #it will utilize the 'pose' and draw the shape approprately according to predesigned dot coord that will be fix\n",
    "        #to the body\n",
    "        #'POSE_CONNECTIONS' helps determine which landmark represents which part of the body\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "        \n",
    "        #separate window will pop open to show the video feed from 'image'\n",
    "        #'Live Feed' is the name of the window\n",
    "        cv2.imshow('Live Feed', image)\n",
    "\n",
    "        #how to turn it off\n",
    "        #the 'e' or 'E' letter will exit the live feed window\n",
    "        if cv2.waitKey(10) & 0xFF == ord('e' or 'E'):\n",
    "            break\n",
    "    #release the camera feed\n",
    "    cap.release()\n",
    "    #close the window\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a377090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOWN\n"
     ]
    }
   ],
   "source": [
    "print(left_lat_raise_stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59a71b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
